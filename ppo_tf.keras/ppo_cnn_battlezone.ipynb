{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ppo_cnn_battlezone",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdubqtMKQ9i5XmB6AOPGwG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rootAkash/reinforcement_learning/blob/master/ppo_tf.keras/ppo_cnn_battlezone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym_Z5Z_upEDa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqOVgu2CWjx3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1309b2e4-c22f-43ad-9584-a305637279c7"
      },
      "source": [
        "!pip install gym[all]\n",
        "!pip install box2d-py\n",
        "!apt-get install python-opengl -y\n",
        "!apt install xvfb -y\n",
        "\n",
        "# Special gym environment\n",
        "#!pip install gym[atari]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym[all] in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[all]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[all]) (1.18.4)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[all]) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[all]) (1.4.1)\n",
            "Requirement already satisfied: imageio; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from gym[all]) (2.4.1)\n",
            "Collecting mujoco-py<2.0,>=1.50; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/8c/64e0630b3d450244feef0688d90eab2448631e40ba6bdbd90a70b84898e7/mujoco-py-1.50.1.68.tar.gz (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from gym[all]) (4.1.2.30)\n",
            "Collecting box2d-py~=2.3.5; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: atari-py~=0.2.0; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from gym[all]) (0.2.6)\n",
            "Requirement already satisfied: Pillow; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from gym[all]) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[all]) (0.16.0)\n",
            "Collecting glfw>=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/03/30603dd2f3af440b41e481382c8b0f102de2c33f339b5ef1dee923260238/glfw-1.11.1-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 13.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.6/dist-packages (from mujoco-py<2.0,>=1.50; extra == \"all\"->gym[all]) (0.29.18)\n",
            "Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.6/dist-packages (from mujoco-py<2.0,>=1.50; extra == \"all\"->gym[all]) (1.14.0)\n",
            "Collecting lockfile>=0.12.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/22/9460e311f340cb62d26a38c419b1381b8593b0bb6b5d1f056938b086d362/lockfile-0.12.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from atari-py~=0.2.0; extra == \"all\"->gym[all]) (1.12.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.10->mujoco-py<2.0,>=1.50; extra == \"all\"->gym[all]) (2.20)\n",
            "Building wheels for collected packages: mujoco-py\n",
            "  Building wheel for mujoco-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for mujoco-py\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for mujoco-py\n",
            "Failed to build mujoco-py\n",
            "Installing collected packages: glfw, lockfile, mujoco-py, box2d-py\n",
            "    Running setup.py install for mujoco-py ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-zevmxqsd/mujoco-py/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-zevmxqsd/mujoco-py/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-19b7s44a/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n",
            "Collecting box2d-py\n",
            "  Using cached https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl\n",
            "0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 496 kB of archives.\n",
            "After this operation, 5,416 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Fetched 496 kB in 1s (747 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 144439 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.4 [784 kB]\n",
            "Fetched 784 kB in 1s (1,109 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 146794 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvwBsGWG4h6l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "326d9d75-1260-44e1-e5a9-a4691443b274"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "%cd /gdrive/My Drive/ll_clean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/ll_clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMNWgIQ1ncIK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83f65b83-a1bc-40cc-aa56-46b9cf36f96f"
      },
      "source": [
        "#retro isnt working so atari\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gym\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "env=gym.make(\"BattleZone-v0\")\n",
        "env=env.unwrapped#removes step restriction\n",
        "\n",
        "s_dim =(50,50,3) #senv.observation_space.shape[0]\n",
        "print(s_dim)\n",
        "a_dim = env.action_space.n\n",
        "print(a_dim)\n",
        "#a_bound = env.action_space.high\n",
        "#print(a_bound)\n",
        "DUMMY_ACTION, DUMMY_VALUE = np.zeros((1,a_dim)), np.zeros((1, 1))\n",
        "\n",
        "\n",
        "\n",
        "state_inputs = tf.keras.Input(shape=(50,50,3), name='state')\n",
        "advantage = tf.keras.Input(shape=(1, ), name=\"Advantage\")\n",
        "old_prediction = tf.keras.Input(shape=(a_dim,), name=\"Old_Prediction\")\n",
        "\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(state_inputs)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(2,2), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(2,2), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(64*2, activation='relu')(x)\n",
        "action_outputs = tf.keras.layers.Dense(a_dim, activation='softmax')(x)\n",
        "\n",
        "\n",
        "def proximal_policy_optimization_loss(advantage, old_prediction):\n",
        "\tloss_clipping = 0.2\n",
        "\tentropy_loss = 0.0\n",
        "\t#y_true = one hot actions , y_pred = prob output\n",
        "\tdef loss(y_true, y_pred):\n",
        "\t\tprob = y_true * y_pred\n",
        "\t\told_prob = y_true * old_prediction\n",
        "\t\tr = prob / (old_prob + 1e-10)\n",
        "\t\tloss = -tf.keras.backend.mean(tf.keras.backend.minimum(r * advantage, tf.keras.backend.clip(r, min_value=1 - loss_clipping,max_value=1 + loss_clipping) * advantage) + entropy_loss * (prob * tf.keras.backend.log(prob + 1e-10)))\n",
        "\t\treturn loss\n",
        "\treturn loss\t\n",
        "policy= tf.keras.Model(inputs=[state_inputs, advantage, old_prediction], outputs=[action_outputs], name='p_actor_model')\n",
        "policy.compile(loss=proximal_policy_optimization_loss(advantage=advantage,old_prediction=old_prediction), optimizer=tf.keras.optimizers.Adam(lr=0.00001))# custom lAdam(lr=0.0001) to be defined\n",
        "policy.summary()\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(state_inputs)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(2,2), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(2,2), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(1,1), padding='valid', activation='relu')(x)\n",
        "\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(64*2, activation='relu')(x)\n",
        "value_outputs = tf.keras.layers.Dense(1, activation=None)(x)\n",
        "critic= tf.keras.Model(inputs=state_inputs, outputs=value_outputs, name='p_critic_model')\n",
        "critic.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
        "critic.summary()\n",
        "\n",
        "\n",
        "def max(a,b):\n",
        "\tif a>b:\n",
        "\t\treturn a\n",
        "\telse:\n",
        "\t\treturn b\n",
        "def abs(a):\n",
        "\tif a>=0:\n",
        "\t\treturn a\n",
        "\telse:\n",
        "\t\treturn -a\n",
        "\n",
        "\n",
        "class Memory:\n",
        "\tdef __init__(self):\n",
        "\t\tself.batch_s = []\n",
        "\t\tself.batch_a = []\n",
        "\t\tself.batch_r = []\n",
        "\t\tself.batch_s_ = []\n",
        "\t\tself.batch_done = []\n",
        "\t\tself.batch_pred =[]\n",
        "\n",
        "\tdef store(self, s, a, s_, r, done,pred):\n",
        "\t\tself.batch_s.append(s)\n",
        "\t\tself.batch_a.append(a)\n",
        "\t\tself.batch_r.append(r)\n",
        "\t\tself.batch_s_.append(s_)\n",
        "\t\tself.batch_done.append(done)\n",
        "\t\tself.batch_pred.append(pred)    \n",
        "\n",
        "\tdef clear(self):\n",
        "\t\tself.batch_s.clear()\n",
        "\t\tself.batch_a.clear()\n",
        "\t\tself.batch_r.clear()\n",
        "\t\tself.batch_s_.clear()\n",
        "\t\tself.batch_done.clear()\n",
        "\t\tself.batch_pred.clear()    \n",
        "\n",
        "\tdef cnt_samples(self):\n",
        "\t\treturn len(self.batch_s)\n",
        "def onehot(a,s):\n",
        "\ti = np.zeros(a_dim)\n",
        "\ti[a]=1\n",
        "\treturn i\n",
        "def save_weights():\n",
        "\tactorpath=\"/gdrive/My Drive/ll_clean/ppo_cnn_battle_zone_A.h5\"\n",
        "\tcriticpath=\"/gdrive/My Drive/ll_clean/ppo_cnn_battle_zone_C.h5\"\n",
        "\tpolicy.save_weights(actorpath)\n",
        "\tcritic.save_weights(criticpath)\n",
        "\tprint(\"saved\")\n",
        "def load_weights():\n",
        "\tactorpath=\"/gdrive/My Drive/ll_clean/ppo_cnn_battle_zone_A.h5\"\n",
        "\tcriticpath=\"/gdrive/My Drive/ll_clean/ppo_cnn_battle_zone_C.h5\"\n",
        "\tpolicy.load_weights(actorpath)\n",
        "\tcritic.load_weights(criticpath)\n",
        "\tprint(\"loaded\")\n",
        "\n",
        "def gae_calc(val,val_,rew,done):\n",
        "\tmask=1 \n",
        "\tgae=0\n",
        "\tgamma=0.99\n",
        "\tlambd = 0.95\n",
        "\treturns=np.zeros_like(val)\n",
        "\tfor i in reversed(range(0,len(val))):\n",
        "\t\tmask=1\n",
        "\t\tif done[i]:\n",
        "\t\t\tmask = 0 \t\n",
        "\t\tdelta=rew[i]+gamma*val_[i]*mask - val[i]\n",
        "\t\tgae=delta+gamma*lambd*mask*gae\n",
        "\t\treturns[i]=gae+val[i]\n",
        "\treturn returns\n",
        "#############################################################################################################\t\n",
        "def preprocess(state):\n",
        "\tstate= state[55:155,:,:]\n",
        "\tstate = cv2.resize( state, (50,50) )\n",
        "\treturn state/225.0\n",
        "\n",
        "load_weights()\n",
        "\n",
        "episodes = 3000\n",
        "steps = 5000\n",
        "memory=Memory()\n",
        "render=0\n",
        "s=env.reset()\n",
        "avg = []\n",
        "t = time.time()\n",
        "for episode in range(1,episodes):\n",
        "\t\n",
        "\tstp = 0 \n",
        "\tdone =False\n",
        "\ts=env.reset()\n",
        "\ts = preprocess(s)\n",
        "\trew = 0 \t\n",
        "\tif episode>2000:\n",
        "\t\trender=0\n",
        "\t\t\n",
        "\twhile not done:\n",
        "\t\tif render:\n",
        "\t\t\tenv.render()\n",
        "\t\t\t#time.sleep(0.01)\n",
        "\t\tpred_action = policy.predict([np.array([s]),DUMMY_VALUE,DUMMY_ACTION])# prob distribution\n",
        "\t\taction = np.random.choice(np.arange(pred_action.shape[1]), p=pred_action.ravel())# action chosen\n",
        "\t\t#random_action= np.random.choice(np.arange(pred_action.shape[1]))\n",
        "\t\t#if steps% 2 == 0 and episode<100:\n",
        "\t\t#\taction = random_action\n",
        "\t\taction_one_hot=onehot(action,a_dim)# acton matrix\n",
        "\t\ts_, reward, done, info = env.step(action)\n",
        "\n",
        "\t\ts_ = preprocess(s_)\t\n",
        "\t\tmemory.store(s,action_one_hot.ravel(),s_,reward,done,pred_action.ravel())# s, a, s_, r, done ,pred\n",
        "\t\tif stp> steps:\n",
        "\t\t\tdone =True \n",
        "\t\ts=s_\n",
        "\t\trew+=reward\n",
        "\t\tstp+=1\n",
        "\t# updation\n",
        "\tavg.append(rew)\n",
        "\tobs =np.array( memory.batch_s)\n",
        "\tvalues = critic.predict(np.array(memory.batch_s))\n",
        "\tvalues_ = critic.predict(np.array(memory.batch_s_))\n",
        "\treturns = gae_calc(values,values_,memory.batch_r,memory.batch_done)\t\n",
        "\tadvantage=returns-values\n",
        "\told_Prediction=memory.batch_pred\n",
        "\told_Prediction=np.array(old_Prediction)\n",
        "\taction=np.array(memory.batch_a)########################\n",
        "\t#print(\".\")\n",
        "\t#print(episode)\n",
        "\tpolicy.fit(x=[obs,advantage, old_Prediction],y=action,batch_size=64,shuffle=True, epochs=10, verbose=False)\n",
        "\tcritic.fit([obs],[returns], batch_size=64, shuffle=True, epochs=10, verbose=False)\n",
        "\t#print(actor_loss,critic_loss)\n",
        "\tmemory.clear()\n",
        "\tif episode % 100== 0:\n",
        "\t\tprint(\"current \",episode , \" average of last 100 episodes :\", np.mean(np.array(avg)), \" max:\", np.max(np.array(avg)), \" min:\", np.min(np.array(avg)) )\n",
        "\t\tavg.clear()\n",
        "\t\tprint(\" total time taken (min): \" ,(time.time()-t)/60)\n",
        "\t\tsave_weights()\n",
        "\t\tt = time.time()\n",
        "  \n",
        "\t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 50, 3)\n",
            "18\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"p_actor_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "state (InputLayer)              [(None, 50, 50, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 48, 48, 64)   1792        state[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 46, 46, 64)   36928       conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 22, 22, 64)   36928       conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 20, 20, 64)   36928       conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 9, 9, 64)     36928       conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 7, 7, 64)     36928       conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 5, 5, 64)     36928       conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 3, 3, 64)     36928       conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 1, 1, 64)     36928       conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          8320        flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Advantage (InputLayer)          [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Old_Prediction (InputLayer)     [(None, 18)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 18)           2322        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 307,858\n",
            "Trainable params: 307,858\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"p_critic_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "state (InputLayer)           [(None, 50, 50, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 48, 48, 64)        1792      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 46, 46, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 22, 22, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 20, 20, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 5, 5, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 1, 1, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 305,665\n",
            "Trainable params: 305,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "loaded\n",
            "current  100  average of last 100 episodes : 26020.0  max: 55000.0  min: 9000.0\n",
            " total time taken (min):  24.50630710919698\n",
            "saved\n",
            "current  200  average of last 100 episodes : 25890.0  max: 42000.0  min: 3000.0\n",
            " total time taken (min):  25.941963044802346\n",
            "saved\n",
            "current  300  average of last 100 episodes : 24460.0  max: 41000.0  min: 4000.0\n",
            " total time taken (min):  28.126695708433786\n",
            "saved\n",
            "current  400  average of last 100 episodes : 21320.0  max: 37000.0  min: 4000.0\n",
            " total time taken (min):  25.45138615767161\n",
            "saved\n",
            "current  500  average of last 100 episodes : 22820.0  max: 49000.0  min: 5000.0\n",
            " total time taken (min):  25.910475850105286\n",
            "saved\n",
            "current  600  average of last 100 episodes : 26820.0  max: 44000.0  min: 4000.0\n",
            " total time taken (min):  26.481936466693877\n",
            "saved\n",
            "current  700  average of last 100 episodes : 22170.0  max: 37000.0  min: 10000.0\n",
            " total time taken (min):  24.595745929082234\n",
            "saved\n",
            "current  800  average of last 100 episodes : 20480.0  max: 37000.0  min: 5000.0\n",
            " total time taken (min):  26.36246427297592\n",
            "saved\n",
            "current  900  average of last 100 episodes : 20340.0  max: 35000.0  min: 4000.0\n",
            " total time taken (min):  26.919845660527546\n",
            "saved\n",
            "current  1000  average of last 100 episodes : 20260.0  max: 31000.0  min: 4000.0\n",
            " total time taken (min):  26.102724778652192\n",
            "saved\n",
            "current  1100  average of last 100 episodes : 21300.0  max: 35000.0  min: 7000.0\n",
            " total time taken (min):  24.84092491865158\n",
            "saved\n",
            "current  1200  average of last 100 episodes : 21850.0  max: 34000.0  min: 9000.0\n",
            " total time taken (min):  25.65841567516327\n",
            "saved\n",
            "current  1300  average of last 100 episodes : 22300.0  max: 38000.0  min: 9000.0\n",
            " total time taken (min):  27.280036373933157\n",
            "saved\n",
            "current  1400  average of last 100 episodes : 21430.0  max: 41000.0  min: 10000.0\n",
            " total time taken (min):  26.030566159884135\n",
            "saved\n",
            "current  1500  average of last 100 episodes : 22530.0  max: 45000.0  min: 9000.0\n",
            " total time taken (min):  27.65286954641342\n",
            "saved\n",
            "current  1600  average of last 100 episodes : 23150.0  max: 39000.0  min: 4000.0\n",
            " total time taken (min):  28.393250767389933\n",
            "saved\n",
            "current  1700  average of last 100 episodes : 23060.0  max: 43000.0  min: 14000.0\n",
            " total time taken (min):  26.768593076864878\n",
            "saved\n",
            "current  1800  average of last 100 episodes : 21670.0  max: 39000.0  min: 5000.0\n",
            " total time taken (min):  26.550123540560403\n",
            "saved\n",
            "current  1900  average of last 100 episodes : 21050.0  max: 34000.0  min: 6000.0\n",
            " total time taken (min):  24.544248282909393\n",
            "saved\n",
            "current  2000  average of last 100 episodes : 19510.0  max: 32000.0  min: 5000.0\n",
            " total time taken (min):  24.337961546579997\n",
            "saved\n",
            "current  2100  average of last 100 episodes : 21450.0  max: 43000.0  min: 4000.0\n",
            " total time taken (min):  24.391543813546498\n",
            "saved\n",
            "current  2200  average of last 100 episodes : 21430.0  max: 35000.0  min: 4000.0\n",
            " total time taken (min):  24.425572117169697\n",
            "saved\n",
            "current  2300  average of last 100 episodes : 20630.0  max: 38000.0  min: 7000.0\n",
            " total time taken (min):  24.24622914393743\n",
            "saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EH4l5jQpxi5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}